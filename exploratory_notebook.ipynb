{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations with IBM\n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Exploratory Data Analysis](#Exploratory-Data-Analysis)<br>\n",
    "II. [Rank Based Recommendations](#Rank)<br>\n",
    "III. [User-User Based Collaborative Filtering](#User-User)<br>\n",
    "IV. [Content Based Recommendations](#Content-Recs)<br>\n",
    "V. [Matrix Factorization](#Matrix-Fact)<br>\n",
    "VI. [Extras & Concluding](#conclusions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...   \n",
       "1      1314.0       healthcare python streaming application demo   \n",
       "2      1429.0         use deep learning for image classification   \n",
       "3      1338.0          ml optimization using cognitive assistant   \n",
       "4      1276.0          deploy your python model as a restful api   \n",
       "\n",
       "                                      email  \n",
       "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7  \n",
       "1  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b  \n",
       "2  b96a4f2e92d8572034b1e9b28f9ac673765cd074  \n",
       "3  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7  \n",
       "4  f01220c46fc92c6e6b161b1849de11faacd7ccb2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import project_tests as t\n",
    "import pickle\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# Show df to get an idea of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "1  See the forest, see the trees. Here lies the c...   \n",
       "2  Here’s this week’s news in Data Science and Bi...   \n",
       "3  Learn how distributed DBs solve the problem of...   \n",
       "4  This video demonstrates the power of IBM DataS...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live           0  \n",
       "1  Communicating data science: A guide to present...       Live           1  \n",
       "2         This Week in Data Science (April 18, 2017)       Live           2  \n",
       "3  DataLayer Conference: Boost the performance of...       Live           3  \n",
       "4      Analyze NY Restaurant data using Spark in DSX       Live           4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">Part I : Exploratory Data Analysis</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5148 users.\n"
     ]
    }
   ],
   "source": [
    "number_of_users = df['email'].nunique()\n",
    "print(\"There are {} users.\".format(number_of_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We still have 5148 users.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.930847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.802267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>364.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id\n",
       "count  5148.000000\n",
       "mean      8.930847\n",
       "std      16.802267\n",
       "min       1.000000\n",
       "25%       1.000000\n",
       "50%       3.000000\n",
       "75%       9.000000\n",
       "max     364.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of articles each email has interacted with \n",
    "user_interact = df[['email','article_id']].groupby(['email']).count() \n",
    "# Make sure we didnt lose anybody \n",
    "print('We still have {} users.'.format(len(user_interact)))\n",
    "\n",
    "user_interact.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5cbd93eac8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creates histogram of number of articles users have seen \n",
    "bins = [0,1,2,3,4,5,10,15,20,30,40,50,60,70,80,90,100]\n",
    "xticks = [0,10,20,30,40,50,60,70,80,90,100]\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(user_interact['article_id'], bins = bins);\n",
    "plt.ylabel('Number of Users');\n",
    "plt.xlabel('Number of Articles Viewed');\n",
    "plt.title('User Interaction with Articles');\n",
    "plt.xticks(xticks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From this histogram we can see that the data is clearly right skewed with most users having viewed less than 10 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% of individuals interact with 3 number of articles or fewer.\n",
      "The average number of articles that a user has interacted with is 9.\n",
      "The maximum number of user-article interactions by any 1 user is 364.\n"
     ]
    }
   ],
   "source": [
    "# Median, mean, max\n",
    "median_val = user_interact['article_id'].median();\n",
    "mean_val = user_interact['article_id'].mean();\n",
    "max_views_by_user = user_interact['article_id'].max();\n",
    "\n",
    "print(f'50% of individuals interact with {median_val.astype(int)} number of articles or fewer.')\n",
    "print(f'The average number of articles that a user has interacted with is {np.around(mean_val).astype(int)}.')\n",
    "print(f'The maximum number of user-article interactions by any 1 user is {max_views_by_user}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The duplicated article ids are [ 50 221 398 577 232]\n",
      "The duplicated titles are\n",
      " ['Graph-based machine learning'\n",
      " 'How smart catalogs can turn the big data flood into an ocean of opportunity'\n",
      " 'Using Apache Spark as a parallel processing framework for accessing REST based data services'\n",
      " 'Use the Primary Index'\n",
      " 'Self-service data preparation with IBM Data Refinery']\n"
     ]
    }
   ],
   "source": [
    "# Find duplicates\n",
    "duplicates = df_content.duplicated(subset='article_id', keep = 'first')\n",
    "duplicated_ids = df_content['article_id'][duplicates]\n",
    "duplicated_names = df_content['doc_full_name'][duplicates]\n",
    "print(\"The duplicated article ids are \" + str(duplicated_ids.values))\n",
    "print(\"The duplicated titles are\\n \"  +str(duplicated_names.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df_content = df_content.drop_duplicates(subset='article_id', keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            email\n",
       "article_id       \n",
       "0.0            14\n",
       "2.0            58\n",
       "4.0            13\n",
       "8.0            85\n",
       "9.0            10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of users that have interacted with each article\n",
    "interaction_article = df[['article_id','email']].groupby(['article_id']).count()\n",
    "interaction_article.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of unique articles that have at least one interaction\n",
    "unique_articles = interaction_article[interaction_article['email'] >= 1].shape[0]\n",
    "# Number of articles \n",
    "total_articles = df_content.shape[0]\n",
    "# The number of unique users\n",
    "unique_users = df[~df['email'].isnull()]['email'].nunique()\n",
    "# The number of user-article interactions\n",
    "user_article_interactions = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique articles that have been interacted with atleast once is 714.\n",
      "The total number of articles is 1051.\n",
      "The number of unique users is 5148.\n",
      "The number of user-article interactions is 45993.\n"
     ]
    }
   ],
   "source": [
    "print('The number of unique articles that have been interacted with atleast once is {}.'.format(unique_articles))\n",
    "print('The total number of articles is {}.'.format(total_articles))\n",
    "print('The number of unique users is {}.'.format(unique_users))\n",
    "print('The number of user-article interactions is {}.'.format(user_article_interactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times each article has been interacted with\n",
    "article_interactions = df['article_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article id of the most viewed article is: 1429.0.\n",
      "The article with the most view had 937 views.\n"
     ]
    }
   ],
   "source": [
    "most_viewed_article_id = article_interactions.index[0]\n",
    "max_views = article_interactions.values[0]\n",
    "print('The article id of the most viewed article is: {}.'.format(most_viewed_article_id))\n",
    "print('The article with the most view had {} views.'.format(max_views.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...        1\n",
       "1      1314.0       healthcare python streaming application demo        2\n",
       "2      1429.0         use deep learning for image classification        3\n",
       "3      1338.0          ml optimization using cognitive assistant        4\n",
       "4      1276.0          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Udacity provided this function to assign each email a unique user_id\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[937, 927, 671, 643, 627, 614, 572, 565, 512, 483]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_article_interactions = list(df['article_id'].value_counts().head(10))\n",
    "n_article_interactions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Rank\">Part II: Rank-Based Recommendations</a>\n",
    "\n",
    "#### This recommendation returns the most popular articles throughout the community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    n_article_interactions = df['article_id'].value_counts().head(n)\n",
    "    top_idx = n_article_interactions.index\n",
    "    top_articles = list(df.loc[df['article_id'].isin(top_idx),:]['title'].unique())\n",
    "    \n",
    "    return top_articles\n",
    "\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    top_article_ids = list(df['article_id'].value_counts().head(n))\n",
    "    \n",
    "    return top_article_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['healthcare python streaming application demo', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization']\n",
      "[937, 927, 671, 643, 627, 614, 572, 565, 512, 483]\n"
     ]
    }
   ],
   "source": [
    "print(get_top_articles(10))\n",
    "print(get_top_article_ids(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top_5 looks like the solution list! Nice job.\n",
      "Your top_10 looks like the solution list! Nice job.\n",
      "Your top_20 looks like the solution list! Nice job.\n"
     ]
    }
   ],
   "source": [
    "# Test your function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of your three lists from above\n",
    "t.sol_2_test(get_top_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"User-User\">Part III: User-User Based Collaborative Filtering</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These recommendations will  be based off of the articles that other users with similar reading habits have read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates indicator matrix for if a user has read an article\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    user_item = df.groupby(['user_id', 'article_id'])['article_id'].count().unstack()\n",
    "    user_item = user_item.fillna(0)\n",
    "    \n",
    "    for column in user_item.columns:\n",
    "         user_item[column] = user_item[column].apply(lambda x: x if x==0 else 1)\n",
    "    return user_item  \n",
    "\n",
    "user_item = create_user_item_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed\n"
     ]
    }
   ],
   "source": [
    "## Tests, udacity provided corrct values \n",
    "assert user_item.shape[0] == 5149, \"The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"The number of articles in the user-article matrix doesn't look right.\"\n",
    "assert user_item.sum(axis=1)[1] == 36, \"The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"Tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds users with similar reading habits to the given user\n",
    "def find_similar_users(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    \n",
    "    '''\n",
    "    sim_users = np.dot(user_item, user_item.T)\n",
    "    index=range(1, sim_users.shape[0]+1)\n",
    "    sim_users=pd.DataFrame(sim_users, index=index, columns=index)\n",
    "    \n",
    "    similar = sim_users[sim_users.index == user_id]\n",
    "    \n",
    "    similar = similar.drop(user_id, axis = 1)\n",
    "    similar = similar.T.sort_values(user_id,ascending=False)\n",
    "    similar_names = similar.index\n",
    "\n",
    "       \n",
    "    return list(similar_names)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [3933, 23, 3782, 203, 4459, 3870, 131, 46, 4201, 395]\n",
      "The 5 most similar users to user 3933 are: [1, 23, 3782, 4459, 203]\n",
      "The 3 most similar users to user 46 are: [4201, 23, 3782]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates article names for a given list of article ID's \n",
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    article_names = df.loc[df['article_id'].isin(article_ids)]['title'].unique()\n",
    "\n",
    "    return article_names \n",
    "\n",
    "# Generates the article ids and article names for each article a user has read \n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the doc_full_name column in df_content)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    article_ids = user_item.columns.values[list(user_item.loc[user_id,] == 1)]\n",
    "    article_ids = article_ids.astype(str)\n",
    "    article_names = get_article_names(article_ids)\n",
    "    return article_ids, article_names \n",
    "\n",
    "# Generates recommendations based off of what similar users have seen\n",
    "def user_user_recs(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    similar_users = find_similar_users(user_id)[:20]\n",
    "    similar_users_seen=[]\n",
    "    for user in similar_users:\n",
    "        articles_seen = get_user_articles(user)[0]\n",
    "        for article in articles_seen:\n",
    "            if article not in similar_users_seen:\n",
    "                similar_users_seen.append(article)\n",
    "            \n",
    "    user_seen = get_user_articles(user_id)[0]        \n",
    "    recs = [item for item in similar_users_seen if item not in user_seen]\n",
    "    \n",
    "    return recs[:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'got zip code data? prep it for analytics. – ibm watson data lab – medium',\n",
       "       'timeseries data analysis of iot events by using jupyter notebook',\n",
       "       'graph-based machine learning',\n",
       "       'using brunel in ipython/jupyter notebooks',\n",
       "       'experience iot with coursera',\n",
       "       'the 3 kinds of context: machine learning and the art of the frame',\n",
       "       'deep forest: towards an alternative to deep neural networks',\n",
       "       'this week in data science (april 18, 2017)',\n",
       "       'higher-order logistic regression for large datasets',\n",
       "       'using machine learning to predict parking difficulty'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return 10 recommendations for user 1\n",
    "get_article_names(user_user_recs(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test functions, Udacity provided correct values\n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"Tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving user recommendations to incorporate number of articles viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the most similar users sorted by similarity, then number of articles viewed\n",
    "\n",
    "\n",
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "\n",
    "     \n",
    "    '''\n",
    "    df_article_views = df[['user_id','article_id']].groupby(['user_id']).count()\n",
    "\n",
    "    similarity = []\n",
    "    for user in range(1, user_item.shape[0]+1):\n",
    "        sim = np.dot(user_item.loc[user_id], user_item.loc[user])\n",
    "        similarity.append((user, sim))\n",
    "\n",
    "        \n",
    "    similarity.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    df_sims = pd.DataFrame()\n",
    "    df_sims['user_id'] = [x[0] for x in similarity]\n",
    "    df_sims['similarity'] = [x[1] for x in similarity]\n",
    "    df_sims = df_sims.set_index('user_id')\n",
    "\n",
    "    df_sims = pd.DataFrame()\n",
    "    df_sims['user_id'] = [x[0] for x in similarity]\n",
    "    df_sims['similarity'] = [x[1] for x in similarity]\n",
    "    df_sims = df_sims.set_index('user_id')\n",
    "\n",
    "\n",
    "\n",
    "    neighbors_df = pd.merge(df_sims,df_article_views, on='user_id')\n",
    "    neighbors_df = neighbors_df[['similarity', 'article_id']]\n",
    "    neighbors_df = neighbors_df.reset_index()\n",
    "    neighbors_df.columns = ['neighbor_id', 'similarity', 'num_articles']\n",
    "    self_idx = neighbors_df[neighbors_df['neighbor_id'] == user_id].index\n",
    "    neighbors_df = neighbors_df.drop(self_idx)\n",
    "    neighbors_df = neighbors_df.sort_values(by=['similarity', 'num_articles'], ascending=False)\n",
    "\n",
    "    return neighbors_df\n",
    "\n",
    "# Generates recommendations based off of similar users that are sorted on similarity and article interactions \n",
    "def user_user_recs_part2(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    '''\n",
    "    similar_users = get_top_sorted_users(user_id)\n",
    "    user_articles_seen = get_user_articles(user_id)[0]\n",
    "    recs = []\n",
    "    for user in similar_users['neighbor_id']:\n",
    "        articles_seen = get_user_articles(user)[0]\n",
    "        if len(recs) < m:\n",
    "            for item in articles_seen:\n",
    "                if item not in user_articles_seen:\n",
    "                    recs.append(item)\n",
    "        else: \n",
    "            break \n",
    "    recs = recs[:m]\n",
    "    rec_names = get_article_names(recs)\n",
    "    \n",
    "    return recs, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbor_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>num_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3933</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>17.0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203</td>\n",
       "      <td>15.0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4459</td>\n",
       "      <td>15.0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbor_id  similarity  num_articles\n",
       "0            1        36.0            47\n",
       "1         3933        35.0            45\n",
       "2           23        17.0           364\n",
       "4          203        15.0           160\n",
       "5         4459        15.0           158"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_test = get_top_sorted_users(3782, df=df, user_item=user_item)\n",
    "similar_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 recommendations for user 20 are the following article ids:\n",
      "['43.0', '109.0', '151.0', '268.0', '310.0', '329.0', '346.0', '390.0', '494.0', '525.0']\n",
      "\n",
      "The top 10 recommendations for user 20 are the following article names:\n",
      "['time series prediction using recurrent neural networks (lstms)'\n",
      " 'jupyter notebook tutorial'\n",
      " 'deep learning with tensorflow course by big data university'\n",
      " 'tensorflow quick tips' 'sector correlations shiny app'\n",
      " 'new shiny cheat sheet and video tutorial'\n",
      " 'introduction to market basket analysis in\\xa0python'\n",
      " 'fighting gerrymandering: using data science to draw fairer congressional districts'\n",
      " 'python for loops explained (python for data science basics #5)'\n",
      " 'introducing ibm watson studio ']\n"
     ]
    }
   ],
   "source": [
    "# Check \n",
    "rec_ids, rec_names = user_user_recs_part2(20, 10)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check \n",
    "user1_most_sim = (get_top_sorted_users(1, df=df, user_item=user_item))['neighbor_id'].iloc[0]# Find the user that is most similar to user 1 \n",
    "user131_10th_sim = get_top_sorted_users(131, df=df, user_item=user_item)['neighbor_id'].iloc[9] # Find the 10th most similar user to user 131\n",
    "user131_10th_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because a new user has no previously viewed content we cannot make any personal inferences about what they might like to watch next. Therefore, the best way to make a recommendation for them is to show them the most popular articles in the community. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Content-Recs\">Part IV: Content Based Recommendations</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tokenize(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    word_tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = []\n",
    "    for token in word_tokens:\n",
    "        clean_token = lemmatizer.lemmatize(token).lower().strip()\n",
    "        clean_tokens.append(clean_token)\n",
    "        \n",
    "    stop_words = set(stopwords.words('english'))    \n",
    "    filtered_tokens = [w for w in clean_tokens if not w in stop_words]\n",
    "    \n",
    "    return filtered_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_content_recs(user_id,n_recs = 10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n_recs - (int) number of articles to recommend\n",
    "    ids - (boolean) True returns article ids, False returns names\n",
    "\n",
    "    OUTPUT:\n",
    "    article_ids or article_names - list of the recommended articles id or name\n",
    "    '''\n",
    "    already_seen = get_user_articles(user_id)[1]\n",
    "    token_titles = []\n",
    "\n",
    "    for title in already_seen:\n",
    "        clean_token = clean_and_tokenize(title)\n",
    "        token_titles.append(clean_token)\n",
    "\n",
    "    unique_token_titles = []\n",
    "    for title in token_titles:\n",
    "        for token in title:\n",
    "            if token not in unique_token_titles:\n",
    "                unique_token_titles.append(token)\n",
    "                \n",
    "    titles_df = df_content[['article_id', 'doc_full_name']]\n",
    "    titles_df.index = df_content['article_id']\n",
    "    titles_df = titles_df.rename(columns={\"doc_full_name\": \"title\"})\n",
    "    titles_df['title_tokens'] = titles_df['title'].apply(lambda x: clean_and_tokenize(x))\n",
    "    titles_df = titles_df.drop('title',axis = 1)\n",
    "    lam_intersect = lambda x: len(set(x).intersection(unique_token_titles))\n",
    "    titles_df['user_similar_tokens'] = titles_df['title_tokens'].apply(lam_intersect)\n",
    "    titles_df = titles_df.sort_values('user_similar_tokens',ascending = False)\n",
    "    \n",
    "    recs = titles_df['article_id'][:n_recs]\n",
    "    recs = recs.values\n",
    "    rec_names = get_article_names(recs, df=df)\n",
    "    return list(recs), list(rec_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([346, 108, 443, 21, 626, 146, 162, 43, 310, 168],\n",
       " ['an introduction to stock market data analysis with r (part 1)',\n",
       "  'time series prediction using recurrent neural networks (lstms)',\n",
       "  '520    using notebooks with pixiedust for fast, flexi...\\nName: title, dtype: object',\n",
       "  'deep learning with tensorflow course by big data university',\n",
       "  'how to use db2 warehouse on cloud in data science experience notebooks',\n",
       "  'analyze db2 warehouse on cloud data in rstudio in dsx',\n",
       "  'load db2 warehouse on cloud data with apache spark in dsx',\n",
       "  'fighting gerrymandering: using data science to draw fairer congressional districts'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_content_recs(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### About make_content_recs() work\n",
    "The content recommendation function that I created breaks the titles that each user has seen into tokens and creates a list of unique tokens. These tokens are then compared to tokenized versions of all article titles and the article titles with the highest number of shared tokens are returned.\n",
    "\n",
    "* This recommendation has a bias towards articles with longer title names\n",
    "* This recommendation does not properly account for users who view multiple articles with similarly worded titles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
